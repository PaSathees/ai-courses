{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning in PySpark\n",
    "\n",
    "Intro\n",
    "\n",
    "Cover basic structure, training and validation split, model selection, pipelines, Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://BAH5CG4421TCH.resource.ds.bah.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Review2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x19434757940>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let's create our PySpark instance\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"Review2\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Data \n",
    "\n",
    "MLlib requires all input columns of your dataframe to be vectorized. You will see that we rename our dependent var to label as that is what is expected for all MLlib applications. If rename once here, we never have to do it again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep function\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "def MLClassifierDFPrep(df,input_columns,dependent_var):\n",
    "    assembler = VectorAssembler(inputCols=input_columns,outputCol='features')\n",
    "    output = assembler.transform(df)\n",
    "    \n",
    "    # change label to string type to prep for reindexing\n",
    "    # Pyspark is expecting a zero indexed integer for the label column. \n",
    "    # Just incase our data is not in that format... we will treat it by using the StringIndexer built in method\n",
    "    renamed = output.withColumn(\"label_str\", df[dependent_var].cast(StringType()))\n",
    "    # print(renamed.printSchema())\n",
    "    indexer = StringIndexer(inputCol=\"label_str\", outputCol=\"label\")\n",
    "    indexed = indexer.fit(renamed).transform(renamed)\n",
    "    #QA\n",
    "    print(\"New DataFrame Format (note new indexing):\")\n",
    "    print(\" \")\n",
    "    indexed.show(5)\n",
    "\n",
    "    final_data = indexed.select('features','label')\n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame Format (note new indexing):\n",
      " \n",
      "+-----------+---------+-----------+---+---+---+--------------------+---------+-----+\n",
      "|flower_type|sepal_len|sepal_width|  R|  G|  B|            features|label_str|label|\n",
      "+-----------+---------+-----------+---+---+---+--------------------+---------+-----+\n",
      "|          3|       69|         57| 56|678|345|[69.0,57.0,56.0,6...|        3|  2.0|\n",
      "|          3|       67|         56| 58|678|345|[67.0,56.0,58.0,6...|        3|  2.0|\n",
      "|          3|       67|         54| 57|678|345|[67.0,54.0,57.0,6...|        3|  2.0|\n",
      "|          3|       68|         55| 58|678|345|[68.0,55.0,58.0,6...|        3|  2.0|\n",
      "|          3|       68|         53| 52|678|345|[68.0,53.0,52.0,6...|        3|  2.0|\n",
      "+-----------+---------+-----------+---+---+---+--------------------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[69.0,57.0,56.0,6...|  2.0|\n",
      "|[67.0,56.0,58.0,6...|  2.0|\n",
      "|[67.0,54.0,57.0,6...|  2.0|\n",
      "|[68.0,55.0,58.0,6...|  2.0|\n",
      "|[68.0,53.0,52.0,6...|  2.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(3,69,57,56,678,345),(3,67,56,58,678,345),(3,67,54,57,678,345),(3,68,55,58,678,345),(3,68,53,52,678,345)\n",
    "                           ,(2,11,10,907,16,458),(2,12,14,909,12,456),(2,11,13,910,10,459),(2,12,11,905,16,459),(2,10,13,902,10,459)\n",
    "                           ,(1,30,11,123,568,891),(1,32,12,124,567,890),(1,34,10,123,566,895),(1,35,15,121,564,894),(1,30,12,124,560,896)], \n",
    "                           ['flower_type', 'sepal_len','sepal_width','R','G','B'])\n",
    "\n",
    "input_columns = ['sepal_len','sepal_width','R','G','B']\n",
    "dependent_var = 'flower_type'\n",
    "\n",
    "final_data = MLClassifierDFPrep(df,input_columns,dependent_var)\n",
    "final_data.show(5)\n",
    "train,test = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification\n",
    "\n",
    "Use this function if your dependent variable (the variable you want to predict) is a descrete value (i.e. whole numbers like 1,2,3,4) typically the dependent variable will represent some class or group like types of flowers or colors, as opposed to a continuous variable like a sales database where every row of data is a transaction and the dependent variable is something like the dollar amount of the sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in sample dataset\n",
    "# final_data = spark.read.format(\"libsvm\").load(\"C:/spark-2.3.3-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\")\n",
    "# train,test = df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,test = df.randomSplit([0.7,0.3])\n",
    "\n",
    "# models = [LinearRegression(),DecisionTreeRegressor(),RandomForestRegressor(),GBTRegressor()]\n",
    "\n",
    "# for model in models:\n",
    "\n",
    "#     # Fit our model\n",
    "#     M = model\n",
    "#     fitModel = M.fit(train)\n",
    "\n",
    "#     # Load the Summary\n",
    "#     trainingSummary = fitModel.summary\n",
    "\n",
    "# #     trainingSummary.residuals.show()\n",
    "#     print(\"Training RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "#     print(\"Training r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def ClassTrainEval(classifier,final_data,features,classes):\n",
    "\n",
    "    def FindMtype(classifier):\n",
    "        # Intstantiate Model\n",
    "        M = classifier\n",
    "        # Learn what it is\n",
    "        Mtype = type(M).__name__\n",
    "        \n",
    "        return Mtype\n",
    "    \n",
    "    Mtype = FindMtype(classifier)\n",
    "    print(Mtype)\n",
    "\n",
    "\n",
    "    def IntanceFitModel(Mtype,classifier,classes,final_data,features):\n",
    "        if Mtype == \"OneVsRest\":\n",
    "            # instantiate the base classifier.\n",
    "            lr = LogisticRegression()\n",
    "            # instantiate the One Vs Rest Classifier.\n",
    "            OVRclassifier = OneVsRest(classifier=lr)\n",
    "            fitModel = OVRclassifier.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            # specify layers for the neural network:\n",
    "            # input layer of size features, two intermediate of features+1 and same size as features\n",
    "            # and output of size number of classes\n",
    "#             features = final_data.select(['features']).collect() #Collecting Results as Python Objects\n",
    "            features_count = len(features[0][0])\n",
    "    #         class_count = final_data.select(F.countDistinct(\"label\"))\n",
    "            layers = [features_count, features_count+1, features_count, classes]\n",
    "            MPC_classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "            fitModel = MPC_classifier.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2: #These classifiers currently only accept binary classification\n",
    "            print(\"Classifier could not be used because it currectly only accepts binary classification data\")\n",
    "            fitModel = \"Not Acceptable\"\n",
    "            return fitModel\n",
    "        if Mtype in(\"LogisticRegression\",\"NaiveBayes\",\"RandomForestClassifier\",\"GBTClassifier\",\"LinearSVC\",\"DecisionTreeClassifier\"):\n",
    "            # Fit Model\n",
    "            fitModel = classifier.fit(train)\n",
    "            return fitModel\n",
    "    \n",
    "    fitModel = IntanceFitModel(Mtype,classifier,classes,final_data,features)\n",
    "    print(fitModel)\n",
    "        \n",
    "    if fitModel != \"Not Acceptable\":\n",
    "        if classes == 0 or classes == 1:\n",
    "            print(\"Not Enough Classes\")\n",
    "        elif classes == 2 and Mtype in(\"LogisticRegression\",\"GBTClassifier\",\"LinearSVC\"):\n",
    "            # Select (prediction, true label) and compute test error\n",
    "            predictionAndLabels = fitModel.evaluate(test)\n",
    "            predictionAndLabels = predictionAndLabels.predictions.select('label','prediction')\n",
    "            Bin_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction') #labelCol='label'\n",
    "            auc = Bin_evaluator.evaluate(predictionAndLabels)\n",
    "            print(Mtype,\" AUC:\",auc)\n",
    "        else:\n",
    "            predictions = fitModel.transform(test)\n",
    "            MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
    "            accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "            print(Mtype,\" Accuracy: {0:.2f}\".format(accuracy),\"%\") #     print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "    else:\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run!\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "classifiers = [LogisticRegression()\n",
    "               ,NaiveBayes(),OneVsRest(),LinearSVC()\n",
    "              ,RandomForestClassifier(),GBTClassifier(),DecisionTreeClassifier()\n",
    "              ,MultilayerPerceptronClassifier()] \n",
    "\n",
    "features = final_data.select(['features']).collect()\n",
    "# Learn how many classes there are in order to specify evaluation type based on binary or multi and turn the df into an object\n",
    "class_count = final_data.select(F.countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "    \n",
    "for classifier in classifiers:\n",
    "    ClassTrainEval(classifier,final_data,features,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.classification import *\n",
    "\n",
    "def ClassDiag(classifier):\n",
    "    \n",
    "    # Fit our model\n",
    "    C = classifier\n",
    "    fitModel = C.fit(train)\n",
    "\n",
    "    # Load the Summary\n",
    "    trainingSummary = fitModel.summary\n",
    "\n",
    "    # General Describe\n",
    "    trainingSummary.predictions.describe().show()\n",
    "\n",
    "    # View Predictions\n",
    "    pred_and_labels = fitModel.evaluate(test)\n",
    "    pred_and_labels.predictions.show()\n",
    "\n",
    "    # Print the coefficients and intercept for multinomial logistic regression\n",
    "    print(\"Coefficients: \\n\" + str(fitModel.coefficientMatrix))\n",
    "    print(\" \")\n",
    "    print(\"Intercept: \" + str(fitModel.interceptVector))\n",
    "    print(\" \")\n",
    "\n",
    "    # Obtain the objective per iteration\n",
    "    objectiveHistory = trainingSummary.objectiveHistory\n",
    "    print(\" \")\n",
    "    print(\"objectiveHistory:\")\n",
    "    for objective in objectiveHistory:\n",
    "        print(objective)\n",
    "\n",
    "    # for multiclass, we can inspect metrics on a per-label basis\n",
    "    print(\" \")\n",
    "    print(\"False positive rate by label:\")\n",
    "    for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "        print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"True positive rate by label:\")\n",
    "    for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "        print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Precision by label:\")\n",
    "    for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "        print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Recall by label:\")\n",
    "    for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "        print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"F-measure by label:\")\n",
    "    for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "        print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "    accuracy = trainingSummary.accuracy\n",
    "    falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "    truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "    fMeasure = trainingSummary.weightedFMeasure()\n",
    "    precision = trainingSummary.weightedPrecision\n",
    "    recall = trainingSummary.weightedRecall\n",
    "    print(\" \")\n",
    "    print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "          % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|             label|        prediction|\n",
      "+-------+------------------+------------------+\n",
      "|  count|                11|                11|\n",
      "|   mean|               1.0|               1.0|\n",
      "| stddev|0.8944271909999159|0.8944271909999159|\n",
      "|    min|               0.0|               0.0|\n",
      "|    max|               2.0|               2.0|\n",
      "+-------+------------------+------------------+\n",
      "\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[68.0,55.0,58.0,6...|  2.0|[-5.5957328177030...|[5.31986839129448...|       2.0|\n",
      "|[11.0,13.0,910.0,...|  1.0|[-5.9167187452156...|[9.79042480321198...|       1.0|\n",
      "|[12.0,14.0,909.0,...|  1.0|[-6.2156086590671...|[7.90920813357862...|       1.0|\n",
      "|[30.0,11.0,123.0,...|  0.0|[14.9548482822278...|[0.99999999957734...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "\n",
      "Coefficients: \n",
      "DenseMatrix([[-0.07782345, -0.18679603, -0.01217995,  0.00674013,  0.01997688],\n",
      "             [-0.05574888,  0.00498522,  0.01685644, -0.0117918 , -0.001897  ],\n",
      "             [ 0.13357234,  0.18181081, -0.0046765 ,  0.00505168, -0.01807988]])\n",
      " \n",
      "Intercept: [-0.7853487194768694,1.0254335236967,-0.2400848042198307]\n",
      " \n",
      " \n",
      "objectiveHistory:\n",
      "1.0904767493577607\n",
      "0.43289366751582725\n",
      "0.10385471041152755\n",
      "0.06023028814182519\n",
      "0.03254833388313952\n",
      "0.016221559554732187\n",
      "0.008189346511856321\n",
      "0.004106962017902152\n",
      "0.002063366417723503\n",
      "0.0010353053166575906\n",
      "0.0005194604466429518\n",
      "0.0002605079799931076\n",
      "0.00013060469885228798\n",
      "6.543925202679384e-05\n",
      "3.282683306580416e-05\n",
      "1.8713289791285412e-05\n",
      "6.084549725312885e-06\n",
      "3.876482656973611e-06\n",
      "1.787985860540237e-06\n",
      "9.297956481514223e-07\n",
      "4.5788969949001057e-07\n",
      "2.2342749824004346e-07\n",
      "1.0233890034395575e-07\n",
      "5.364952102773011e-08\n",
      "2.6439189585144875e-08\n",
      "1.3322946624715438e-08\n",
      "6.6543543200933445e-09\n",
      "3.619298961542551e-09\n",
      "1.0541943076056916e-09\n",
      " \n",
      "False positive rate by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      "label 2: 0.0\n",
      " \n",
      "True positive rate by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "label 2: 1.0\n",
      " \n",
      "Precision by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "label 2: 1.0\n",
      " \n",
      "Recall by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "label 2: 1.0\n",
      " \n",
      "F-measure by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "label 2: 1.0\n",
      " \n",
      "Accuracy: 1.0\n",
      "FPR: 0.0\n",
      "TPR: 1.0\n",
      "F-measure: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# classifier = LogisticRegression()\n",
    "ClassDiag(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "**Note:**\n",
    "We did not include Generalized Linear Regression here since it requires a much different implementation method and evaluation strategy than most regressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the data\n",
    "# df = spark.read.format(\"libsvm\").load(\"C:/spark-2.3.3-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\")\n",
    "# train,test = df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare data prep function\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "def MLRegressDFPrep(df,input_columns,dependent_var):\n",
    "    assembler = VectorAssembler(inputCols=input_columns,outputCol='features')\n",
    "    output = assembler.transform(df)\n",
    "    renamed = output.withColumnRenamed(dependent_var,'label')\n",
    "    final_data = renamed.select('features','label')\n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[72.2,144.0,14.4,...|   96|\n",
      "|[12.5,120.0,12.2,...|   80|\n",
      "|[10.8,108.0,10.8,...|   72|\n",
      "| [7.8,78.0,7.8,49.0]|   52|\n",
      "|[14.55,145.0,14.5...|   97|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(96,72.2,144,14.4,19),\n",
    "                            (80,12.5,120,12.2,68),\n",
    "                            (72,10.8,108,10.8,36),\n",
    "                            (52,7.8,78,7.8,49),\n",
    "                            (97,14.55,145,14.55,63),\n",
    "                            (42,6.3,63,6.3,61),\n",
    "                            (20,3.7,30,3.4,22),\n",
    "                            (5,0.75,7,0.75,24),\n",
    "                            (89,13.35,133,13.35,63),\n",
    "                            (19,2.85,28,2.85,26)], \n",
    "                           ['sales_m', 'advertising_k','employees','locations','compage'])\n",
    "\n",
    "input_columns = ['advertising_k','employees','locations','compage']\n",
    "dependent_var = 'sales_m'\n",
    "\n",
    "final_data = MLRegressDFPrep(df,input_columns,dependent_var)\n",
    "final_data.show(5)\n",
    "train,test = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import *\n",
    "from pyspark.ml.evaluation import *\n",
    "\n",
    "def RegressTrainEval(regressor):\n",
    "\n",
    "    def FindMtype(regressor):\n",
    "        # Intstantiate Model\n",
    "        M = regressor\n",
    "        # Learn what it is\n",
    "        Mtype = type(M).__name__\n",
    "        \n",
    "        return Mtype\n",
    "    \n",
    "    Mtype = FindMtype(regressor)\n",
    "    print(Mtype)\n",
    "\n",
    "\n",
    "#     def Evaluate(Mtype,classifier):\n",
    "\n",
    "    if Mtype == \"LinearRegression\":\n",
    "\n",
    "        # Fit our model\n",
    "        fitModel = regressor.fit(train)\n",
    "\n",
    "        # Load the Summary\n",
    "        trainingSummary = fitModel.summary\n",
    "        \n",
    "        # Print the coefficients and intercept for linear regression\n",
    "        print(\"Coefficients: %s\" % str(fitModel.coefficients))\n",
    "        print(\"Intercept: %s\" % str(fitModel.intercept))\n",
    "        print(\"\")\n",
    "\n",
    "        # Summarize the model over the training set and print out some metrics\n",
    "        print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "        print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "        print(\"\")\n",
    "        \n",
    "        # Print the Errors\n",
    "        print(\"Training RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "        print(\"Training r2: %f\" % trainingSummary.r2)\n",
    "        print(\"\")\n",
    "\n",
    "        # Now load the test results\n",
    "        test_results = fitModel.evaluate(test)\n",
    "\n",
    "        # And print them\n",
    "        print(\"Test RMSE: {}\".format(test_results.rootMeanSquaredError))\n",
    "        print(\"Test r2: {}\".format(test_results.r2))\n",
    "        print(\"\")\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Fit our model\n",
    "        fitModel = regressor.fit(train)\n",
    "                    \n",
    "        # Make predictions.\n",
    "        predictions = fitModel.transform(test)\n",
    "        # Select (prediction, true label) and compute test error\n",
    "        evaluator = RegressionEvaluator(metricName=\"rmse\")\n",
    "        rmse = evaluator.evaluate(predictions)\n",
    "        print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Coefficients: [-0.4903672321785257,1.2264876672553044,-0.9743544462783574,1.8766639577498148,0.6671339513374913,1.7730018647921157,-0.10889904866592723,-0.030261305723280115,-0.7796826355203386,0.20381413983516675]\n",
      "Intercept: -0.021291243629179005\n",
      "\n",
      "numIterations: 1\n",
      "objectiveHistory: [0.0]\n",
      "\n",
      "Training RMSE: 9.849372\n",
      "Training r2: 0.032913\n",
      "\n",
      "Test RMSE: 10.933152836069855\n",
      "Test r2: -0.0007608531921694528\n",
      "\n",
      "RandomForestRegressor\n",
      "Root Mean Squared Error (RMSE) on test data = 11.0362\n",
      "\n",
      "GBTRegressor\n",
      "Root Mean Squared Error (RMSE) on test data = 13.2638\n",
      "\n",
      "DecisionTreeRegressor\n",
      "Root Mean Squared Error (RMSE) on test data = 12.2536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run!\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "regressors = [LinearRegression()\n",
    "              ,RandomForestRegressor(),GBTRegressor(),DecisionTreeRegressor()] \n",
    "    \n",
    "for regressor in regressors:\n",
    "    RegressTrainEval(regressor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
