{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Tracking Example\n",
    "\n",
    "MLflow is organized into four components: **Tracking**, **Projects**, **Models**, and **Model Registry**. You can use each of these components on their own—for example, maybe you want to export models in MLflow’s model format without using Tracking or Projects—but they are also designed to work well together. So this notebook will focus on only the **Tracking** component within the PySpark environment. \n",
    "\n",
    "### Why is tracking useful/important?\n",
    "\n",
    "Machine learning typically requires experimenting with a diverse set of hyperparameter tuning techniques, data preparation steps, and algorithms to build a model that maximizes some target metric. Given this complexity, building a machine learning model can therefore be challenging for a couple of reasons:\n",
    "\n",
    "1. **It’s difficult to keep track of experiments.** When you are just working with files on your laptop, or with an interactive notebook, how do you tell which data, code and parameters went into getting a particular result?\n",
    "2. **It’s difficult to reproduce code.** Even if you have meticulously tracked the code versions and parameters, you need to capture the whole environment (for example, library dependencies) to get the same result again. This is especially challenging if you want another data scientist to use your code, or if you want to run the same code at scale on another platform (for example, in the cloud).\n",
    "\n",
    "### Solution that MLflow Tracking provides\n",
    "\n",
    "MLflow Tracking is an API and UI for logging parameters, code versions, metrics, and artifacts when running your machine learning code and for later visualizing the results. You can use MLflow Tracking in any environment (for example, a standalone script or a notebook) to log results to local files or to a server, then compare multiple runs.\n",
    "\n",
    "### How to install MLflow\n",
    "\n",
    "You simply install MLflow by running *\"pip install mlflow\"* via the command line. Please reference the Quick Start Guide here for more details: https://mlflow.org/docs/latest/quickstart.html\n",
    "\n",
    "### Viewing the Tracking MLflow UI\n",
    "\n",
    "By default, wherever you run your program (Jupyter Notebook in this case), the tracking API writes data into files into a local ./mlruns directory. First you need to open your mlflow intance via the command line (cd into the folder where this notebook is stored). You can then run MLflow’s Tracking UI: http://localhost:5000/#/\n",
    "\n",
    "### How to cd into a folder\n",
    "\n",
    " - **Mac**: https://macpaw.com/how-to/use-terminal-on-mac\n",
    " - **Windows**: https://www.minitool.com/news/how-to-change-directory-in-cmd.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# Mlflow libaries\n",
    "import mlflow\n",
    "\n",
    "# Mlflow client\n",
    "from  mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "# Numpy for random number generator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/py4j/java_collections.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import (\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pyspark/resultiterable.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  class ResultIterable(collections.Iterable):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'mlflow-env',\n",
       " 'channels': ['defaults'],\n",
       " 'dependencies': ['python=3.7.4', 'pyspark=2.4.4', 'pip', {'pip': ['mlflow']}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get info about your environment\n",
    "mlflow.spark.get_default_conda_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Experiments and Runs with the Tracking Service API\n",
    "\n",
    "https://mlflow.org/docs/latest/tracking.html#managing-experiments-and-runs-with-the-tracking-service-api\n",
    "\n",
    "### Organizing Runs in Experiments\n",
    "\n",
    "https://mlflow.org/docs/latest/tracking.html#organizing-runs-in-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create experiement\n",
    "exp_id = mlflow.create_experiment(\"Experiment-4\")\n",
    "# mlflow.create_experiment(\"Experiment-0\")\n",
    "exp_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment\n",
    "# This will actually automatically create one if the one you call on doesn't exist\n",
    "mlflow.set_experiment(experiment_name = \"Experiment-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Experiment: artifact_location='file:///Users/orcuncanlilar/Eden/PySpark%20Essentials%20for%20Data%20Scientists/Jupyter%20Notebooks/Machine%20Learning/mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>\n",
      " \n",
      "<Experiment: artifact_location='file:///Users/orcuncanlilar/Eden/PySpark%20Essentials%20for%20Data%20Scientists/Jupyter%20Notebooks/Machine%20Learning/mlruns/6', experiment_id='6', lifecycle_stage='active', name='Experiment-4', tags={}>\n",
      " \n",
      "<Experiment: artifact_location='file:///Users/orcuncanlilar/Eden/PySpark%20Essentials%20for%20Data%20Scientists/Jupyter%20Notebooks/Machine%20Learning/mlruns/1', experiment_id='1', lifecycle_stage='active', name='first-experiment', tags={'mlflow.note.content': 'This experiment tested various tree classifiers '\n",
      "                        'across various parameters. The training process used '\n",
      "                        'a parameter grid search technique for Hyperparameter '\n",
      "                        'optimization. It was a real success!'}>\n",
      " \n",
      "<Experiment: artifact_location='file:///Users/orcuncanlilar/Eden/PySpark%20Essentials%20for%20Data%20Scientists/Jupyter%20Notebooks/Machine%20Learning/mlruns/4', experiment_id='4', lifecycle_stage='active', name='Experiment-2', tags={}>\n",
      " \n",
      "<Experiment: artifact_location='file:///Users/orcuncanlilar/Eden/PySpark%20Essentials%20for%20Data%20Scientists/Jupyter%20Notebooks/Machine%20Learning/mlruns/3', experiment_id='3', lifecycle_stage='active', name='Experiment-1', tags={}>\n",
      " \n",
      "<Experiment: artifact_location='file:///Users/orcuncanlilar/Eden/PySpark%20Essentials%20for%20Data%20Scientists/Jupyter%20Notebooks/Machine%20Learning/mlruns/2', experiment_id='2', lifecycle_stage='active', name='Experiment-0', tags={}>\n",
      " \n",
      "<Experiment: artifact_location='file:///Users/orcuncanlilar/Eden/PySpark%20Essentials%20for%20Data%20Scientists/Jupyter%20Notebooks/Machine%20Learning/mlruns/5', experiment_id='5', lifecycle_stage='active', name='Experiment-3', tags={}>\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# set up your client and get list of experiments\n",
    "from  mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "experiments = client.list_experiments() # returns a list of mlflow.entities.Experiment\n",
    "for x in experiments:\n",
    "#     print(x.name)\n",
    "    print(x)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Description:  <Experiment: artifact_location='file:///Users/orcuncanlilar/Eden/PySpark%20Essentials%20for%20Data%20Scientists/Jupyter%20Notebooks/Machine%20Learning/mlruns/3', experiment_id='3', lifecycle_stage='active', name='Experiment-1', tags={}>\n",
      " \n",
      "Name:  Experiment-1\n",
      "ID:  3\n",
      "Tags:  {}\n"
     ]
    }
   ],
   "source": [
    "# You can retrieve any of the elements from experiements that you need....\n",
    "print(\"Full Description: \",experiments[2])\n",
    "print(\" \")\n",
    "print(\"Name: \",experiments[2].name)\n",
    "print(\"ID: \",experiments[2].experiment_id)\n",
    "print(\"Tags: \",experiments[2].tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={}, params={}, tags={}>, info=<RunInfo: artifact_uri='file:///Users/orcuncanlilar/Eden/PySpark%20Essentials%20for%20Data%20Scientists/Jupyter%20Notebooks/Machine%20Learning/mlruns/6/86e0d3b013c242a9a223e742583998ab/artifacts', end_time=None, experiment_id='6', lifecycle_stage='active', run_id='86e0d3b013c242a9a223e742583998ab', run_uuid='86e0d3b013c242a9a223e742583998ab', start_time=1589220431918, status='RUNNING', user_id='unknown'>>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a run and attach it to the experiment you just created\n",
    "# Just to the get the general concept down\n",
    "\n",
    "experiement_name = 'Experiment-4'\n",
    "def create_run(experiement_name):\n",
    "    for x in experiments:\n",
    "        if experiement_name in x.name:\n",
    "            experiment_index = experiments.index(x)\n",
    "            run = client.create_run(experiments[experiment_index].experiment_id) # returns mlflow.entities.Run\n",
    "            return run\n",
    "            \n",
    "# Example run:\n",
    "run = create_run(experiement_name)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/orcuncanlilar/Eden/PySpark%20Essentials%20for%20Data%20Scientists/Jupyter%20Notebooks/Machine%20Learning/mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conduct a run!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a new run if you haven't already\n",
    "run = create_run(experiement_name)\n",
    "\n",
    "random_num = np.random.randint(0,500)\n",
    "binary = np.random.randint(0,2)\n",
    "test_id = np.random.randint(0,3000)\n",
    "\n",
    "# Add tag to a run\n",
    "client.set_tag(run.info.run_id,\"Test ID\",test_id)\n",
    "\n",
    "if binary == 0:\n",
    "    result = 'Pass'\n",
    "    client.set_tag(run.info.run_id, \"Result\", result)\n",
    "else:\n",
    "    result = 'Fail'\n",
    "    client.set_tag(run.info.run_id, \"Result\", result)\n",
    "    \n",
    "client.set_tag(run.info.run_id,\"Random Number\",random_num)\n",
    "\n",
    "# Terminate the client\n",
    "client.set_terminated(run.info.run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
