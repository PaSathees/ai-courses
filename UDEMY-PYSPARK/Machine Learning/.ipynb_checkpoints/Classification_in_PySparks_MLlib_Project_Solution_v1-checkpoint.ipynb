{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification in PySpark's MLlib Project Solution\n",
    "\n",
    "Now it's time to leverage what we learned in the lectures to a REAL classification project! For this project we will be classifying songs based on a number of characteristics into a set of 23 electronic genres. This technology could be used by application like Pandora to recommend songs to users or just create meaningful channels. Super fun!\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "First let's create our PySpark instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://orcuns-mbp-2.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Review2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x114f00810>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"Review2\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's read our dataset in for this notebook \n",
    "\n",
    "### Context\n",
    "What makes us, humans, able to tell apart two songs of different genres? Maybe you have ever been in the diffcult situation to explain show it sounds the music style that you like to someone. Then, could an automatic genre classifcation be possible?\n",
    "\n",
    "### Content\n",
    "Each row is an electronic music song. The dataset contains 100 song for each genre among 23 electronic music genres, they were the top (100) songs of their genres on November 2016. The 71 columns are audio features extracted of a two random minutes sample of the file audio. These features have been extracted using pyAudioAnalysis (https://github.com/tyiannak/pyAudioAnalysis).\n",
    "\n",
    "### Source\n",
    "https://www.kaggle.com/caparrini/beatsdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"\"\n",
    "df = spark.read.csv(path+'beatsdataset.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|  skewness(1-ZCRm)|\n",
      "+------------------+\n",
      "|0.2013145096851716|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Would you like to treat for skewness?\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "# First calculate skewness\n",
    "skew = df.agg(f.skewness(\"1-ZCRm\"))\n",
    "kurtosis = df.agg(f.kurtosis(\"1-ZCRm\"))\n",
    "\n",
    "for col in df.columns:\n",
    "    # Next do a log transformation if the distribution is right skewed \n",
    "    # adding a =1 so i dont get errors when x = 0\n",
    "    if skew > 1:\n",
    "        df_new = df.withColumn(col, F.log(df[col]+1).alias(col))\n",
    "        print(col+\" treated for right skew)\n",
    "    #and an exponential transformation if left skewed\n",
    "    if skew < -1:\n",
    "        df_new = df.withColumn(col, F.exp(df[col] +1).alias(col))\n",
    "        print(col+\" treated for left skew)\n",
    "# if kurtosis <-3 or kurtosis >3 or kurtosis in range(-.05,.05):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|1-ZCRm            |2-Energym         |\n",
      "+------------------+------------------+\n",
      "|0.2013145096851716|0.6696401111661872|\n",
      "+------------------+------------------+\n",
      "\n",
      "0.2013145096851716\n",
      "0.6696401111661872\n"
     ]
    }
   ],
   "source": [
    "numeric_inputs = ['1-ZCRm','2-Energym']\n",
    "skew = df.select([f.skewness(c).alias(c) for c in df.columns if c in numeric_inputs]) # Calculate the mins for all columns in the df\n",
    "skew.show(1,False)\n",
    "skew_array = skew.select(array(numeric_inputs).alias(\"skew\"))\n",
    "\n",
    "#get the global min\n",
    "skew_minimum = skew_array.select(array_min(skew_array.skew)).collect() # Collect golobal min as Python object\n",
    "skew_minimum = skew_minimum[0][0] # Slice to get the number itself\n",
    "print(skew_minimum)\n",
    "\n",
    "#get the global max\n",
    "skew_max = skew_array.select(array_max(skew_array.skew)).collect() # Collect golobal min as Python object\n",
    "skew_max = skew_max[0][0] # Slice to get the number itself\n",
    "print(skew_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the dataset\n",
    "\n",
    "Let's produce a print out of the dataframe so we know what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>1-ZCRm</th>\n",
       "      <th>2-Energym</th>\n",
       "      <th>3-EnergyEntropym</th>\n",
       "      <th>4-SpectralCentroidm</th>\n",
       "      <th>5-SpectralSpreadm</th>\n",
       "      <th>6-SpectralEntropym</th>\n",
       "      <th>7-SpectralFluxm</th>\n",
       "      <th>8-SpectralRolloffm</th>\n",
       "      <th>9-MFCCs1m</th>\n",
       "      <th>...</th>\n",
       "      <th>63-ChromaVector8std</th>\n",
       "      <th>64-ChromaVector9std</th>\n",
       "      <th>65-ChromaVector10std</th>\n",
       "      <th>66-ChromaVector11std</th>\n",
       "      <th>67-ChromaVector12std</th>\n",
       "      <th>68-ChromaDeviationstd</th>\n",
       "      <th>69-BPM</th>\n",
       "      <th>70-BPMconf</th>\n",
       "      <th>71-BPMessentia</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136440</td>\n",
       "      <td>0.088861</td>\n",
       "      <td>3.201201</td>\n",
       "      <td>0.262825</td>\n",
       "      <td>0.249212</td>\n",
       "      <td>1.114423</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.256682</td>\n",
       "      <td>-22.723259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.015056</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.132792</td>\n",
       "      <td>128.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117039</td>\n",
       "      <td>0.108389</td>\n",
       "      <td>3.194001</td>\n",
       "      <td>0.247657</td>\n",
       "      <td>0.250288</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.199821</td>\n",
       "      <td>-21.775871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.015499</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.112767</td>\n",
       "      <td>126.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.128525</td>\n",
       "      <td>3.123837</td>\n",
       "      <td>0.217205</td>\n",
       "      <td>0.228652</td>\n",
       "      <td>0.789647</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.156822</td>\n",
       "      <td>-22.472722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.017482</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.022201</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.123373</td>\n",
       "      <td>129.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.103050</td>\n",
       "      <td>0.167042</td>\n",
       "      <td>3.150830</td>\n",
       "      <td>0.233593</td>\n",
       "      <td>0.245032</td>\n",
       "      <td>0.967082</td>\n",
       "      <td>0.006571</td>\n",
       "      <td>0.168083</td>\n",
       "      <td>-21.470751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>0.023162</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.158876</td>\n",
       "      <td>129.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.151730</td>\n",
       "      <td>0.148405</td>\n",
       "      <td>3.194498</td>\n",
       "      <td>0.293730</td>\n",
       "      <td>0.267231</td>\n",
       "      <td>1.353005</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.292055</td>\n",
       "      <td>-21.371157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.011330</td>\n",
       "      <td>0.028188</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.019079</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.190708</td>\n",
       "      <td>129.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.127047</td>\n",
       "      <td>0.153488</td>\n",
       "      <td>3.221987</td>\n",
       "      <td>0.261693</td>\n",
       "      <td>0.257361</td>\n",
       "      <td>1.090034</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.230099</td>\n",
       "      <td>-21.234846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.006533</td>\n",
       "      <td>0.010347</td>\n",
       "      <td>0.025008</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.019479</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.168933</td>\n",
       "      <td>129.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0    1-ZCRm  2-Energym  3-EnergyEntropym  4-SpectralCentroidm  \\\n",
       "0    0  0.136440   0.088861          3.201201             0.262825   \n",
       "1    1  0.117039   0.108389          3.194001             0.247657   \n",
       "2    2  0.085308   0.128525          3.123837             0.217205   \n",
       "3    3  0.103050   0.167042          3.150830             0.233593   \n",
       "4    4  0.151730   0.148405          3.194498             0.293730   \n",
       "5    5  0.127047   0.153488          3.221987             0.261693   \n",
       "\n",
       "   5-SpectralSpreadm  6-SpectralEntropym  7-SpectralFluxm  8-SpectralRolloffm  \\\n",
       "0           0.249212            1.114423         0.007003            0.256682   \n",
       "1           0.250288            1.065668         0.005387            0.199821   \n",
       "2           0.228652            0.789647         0.008247            0.156822   \n",
       "3           0.245032            0.967082         0.006571            0.168083   \n",
       "4           0.267231            1.353005         0.003872            0.292055   \n",
       "5           0.257361            1.090034         0.004943            0.230099   \n",
       "\n",
       "   9-MFCCs1m  ...  63-ChromaVector8std  64-ChromaVector9std  \\\n",
       "0 -22.723259  ...             0.003431             0.004981   \n",
       "1 -21.775871  ...             0.004461             0.006441   \n",
       "2 -22.472722  ...             0.001529             0.004556   \n",
       "3 -21.470751  ...             0.001591             0.003514   \n",
       "4 -21.371157  ...             0.003945             0.004131   \n",
       "5 -21.234846  ...             0.002986             0.006533   \n",
       "\n",
       "   65-ChromaVector10std  66-ChromaVector11std  67-ChromaVector12std  \\\n",
       "0              0.010818              0.024001              0.005201   \n",
       "1              0.007469              0.015499              0.005589   \n",
       "2              0.007723              0.017482              0.002901   \n",
       "3              0.009477              0.023162              0.004165   \n",
       "4              0.011330              0.028188              0.002639   \n",
       "5              0.010347              0.025008              0.003035   \n",
       "\n",
       "   68-ChromaDeviationstd      69-BPM  70-BPMconf  71-BPMessentia    class  \n",
       "0               0.015056  133.333333    0.132792           128.0  BigRoom  \n",
       "1               0.019339  120.000000    0.112767           126.0  BigRoom  \n",
       "2               0.022201  133.333333    0.123373           129.0  BigRoom  \n",
       "3               0.015379  133.333333    0.158876           129.0  BigRoom  \n",
       "4               0.019079  133.333333    0.190708           129.0  BigRoom  \n",
       "5               0.019479  133.333333    0.168933           129.0  BigRoom  \n",
       "\n",
       "[6 rows x 73 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- 1-ZCRm: double (nullable = true)\n",
      " |-- 2-Energym: double (nullable = true)\n",
      " |-- 3-EnergyEntropym: double (nullable = true)\n",
      " |-- 4-SpectralCentroidm: double (nullable = true)\n",
      " |-- 5-SpectralSpreadm: double (nullable = true)\n",
      " |-- 6-SpectralEntropym: double (nullable = true)\n",
      " |-- 7-SpectralFluxm: double (nullable = true)\n",
      " |-- 8-SpectralRolloffm: double (nullable = true)\n",
      " |-- 9-MFCCs1m: double (nullable = true)\n",
      " |-- 10-MFCCs2m: double (nullable = true)\n",
      " |-- 11-MFCCs3m: double (nullable = true)\n",
      " |-- 12-MFCCs4m: double (nullable = true)\n",
      " |-- 13-MFCCs5m: double (nullable = true)\n",
      " |-- 14-MFCCs6m: double (nullable = true)\n",
      " |-- 15-MFCCs7m: double (nullable = true)\n",
      " |-- 16-MFCCs8m: double (nullable = true)\n",
      " |-- 17-MFCCs9m: double (nullable = true)\n",
      " |-- 18-MFCCs10m: double (nullable = true)\n",
      " |-- 19-MFCCs11m: double (nullable = true)\n",
      " |-- 20-MFCCs12m: double (nullable = true)\n",
      " |-- 21-MFCCs13m: double (nullable = true)\n",
      " |-- 22-ChromaVector1m: double (nullable = true)\n",
      " |-- 23-ChromaVector2m: double (nullable = true)\n",
      " |-- 24-ChromaVector3m: double (nullable = true)\n",
      " |-- 25-ChromaVector4m: double (nullable = true)\n",
      " |-- 26-ChromaVector5m: double (nullable = true)\n",
      " |-- 27-ChromaVector6m: double (nullable = true)\n",
      " |-- 28-ChromaVector7m: double (nullable = true)\n",
      " |-- 29-ChromaVector8m: double (nullable = true)\n",
      " |-- 30-ChromaVector9m: double (nullable = true)\n",
      " |-- 31-ChromaVector10m: double (nullable = true)\n",
      " |-- 32-ChromaVector11m: double (nullable = true)\n",
      " |-- 33-ChromaVector12m: double (nullable = true)\n",
      " |-- 34-ChromaDeviationm: double (nullable = true)\n",
      " |-- 35-ZCRstd: double (nullable = true)\n",
      " |-- 36-Energystd: double (nullable = true)\n",
      " |-- 37-EnergyEntropystd: double (nullable = true)\n",
      " |-- 38-SpectralCentroidstd: double (nullable = true)\n",
      " |-- 39-SpectralSpreadstd: double (nullable = true)\n",
      " |-- 40-SpectralEntropystd: double (nullable = true)\n",
      " |-- 41-SpectralFluxstd: double (nullable = true)\n",
      " |-- 42-SpectralRolloffstd: double (nullable = true)\n",
      " |-- 43-MFCCs1std: double (nullable = true)\n",
      " |-- 44-MFCCs2std: double (nullable = true)\n",
      " |-- 45-MFCCs3std: double (nullable = true)\n",
      " |-- 46-MFCCs4std: double (nullable = true)\n",
      " |-- 47-MFCCs5std: double (nullable = true)\n",
      " |-- 48-MFCCs6std: double (nullable = true)\n",
      " |-- 49-MFCCs7std: double (nullable = true)\n",
      " |-- 50-MFCCs8std: double (nullable = true)\n",
      " |-- 51-MFCCs9std: double (nullable = true)\n",
      " |-- 52-MFCCs10std: double (nullable = true)\n",
      " |-- 53-MFCCs11std: double (nullable = true)\n",
      " |-- 54-MFCCs12std: double (nullable = true)\n",
      " |-- 55-MFCCs13std: double (nullable = true)\n",
      " |-- 56-ChromaVector1std: double (nullable = true)\n",
      " |-- 57-ChromaVector2std: double (nullable = true)\n",
      " |-- 58-ChromaVector3std: double (nullable = true)\n",
      " |-- 59-ChromaVector4std: double (nullable = true)\n",
      " |-- 60-ChromaVector5std: double (nullable = true)\n",
      " |-- 61-ChromaVector6std: double (nullable = true)\n",
      " |-- 62-ChromaVector7std: double (nullable = true)\n",
      " |-- 63-ChromaVector8std: double (nullable = true)\n",
      " |-- 64-ChromaVector9std: double (nullable = true)\n",
      " |-- 65-ChromaVector10std: double (nullable = true)\n",
      " |-- 66-ChromaVector11std: double (nullable = true)\n",
      " |-- 67-ChromaVector12std: double (nullable = true)\n",
      " |-- 68-ChromaDeviationstd: double (nullable = true)\n",
      " |-- 69-BPM: double (nullable = true)\n",
      " |-- 70-BPMconf: double (nullable = true)\n",
      " |-- 71-BPMessentia: double (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many classes do we have?\n",
    "\n",
    "Just making sure :) \n",
    "\n",
    "We have a perfectly balanced dataset! \n",
    "\n",
    "*Note: This never happens in real life :)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               class|count|\n",
      "+--------------------+-----+\n",
      "|           PsyTrance|  100|\n",
      "|           HardDance|  100|\n",
      "|              Breaks|  100|\n",
      "|  HardcoreHardTechno|  100|\n",
      "|   IndieDanceNuDisco|  100|\n",
      "|              Trance|  100|\n",
      "|           DeepHouse|  100|\n",
      "|ElectronicaDowntempo|  100|\n",
      "|           ReggaeDub|  100|\n",
      "|             Minimal|  100|\n",
      "|         DrumAndBass|  100|\n",
      "|             Dubstep|  100|\n",
      "|             BigRoom|  100|\n",
      "|              Techno|  100|\n",
      "|               House|  100|\n",
      "|         FutureHouse|  100|\n",
      "|        ElectroHouse|  100|\n",
      "|           GlitchHop|  100|\n",
      "|           TechHouse|  100|\n",
      "|              HipHop|  100|\n",
      "|           FunkRAndB|  100|\n",
      "|               Dance|  100|\n",
      "|    ProgressiveHouse|  100|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"class\").count().show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Data \n",
    "\n",
    "MLlib requires all input columns of your dataframe to be vectorized. You will see that we rename our dependent var to label as that is what is expected for all MLlib applications. If rename once here, we never have to do it again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and create a function to do all of this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in functions we will need\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Data Prep function\n",
    "def MLClassifierDFPrep(df,input_columns,dependent_var):\n",
    "    \n",
    "    # change label (class variable) to string type to prep for reindexing\n",
    "    # Pyspark is expecting a zero indexed integer for the label column. \n",
    "    # Just incase our data is not in that format... we will treat it by using the StringIndexer built in method\n",
    "    renamed = df.withColumn(\"label_str\", df[dependent_var].cast(StringType())) #Rename and change to string type\n",
    "    indexer = StringIndexer(inputCol=\"label_str\", outputCol=\"label\") #Pyspark is expecting the this naming convention \n",
    "    indexed = indexer.fit(renamed).transform(renamed)\n",
    "\n",
    "    # Convert all string type data in the input column list to numeric\n",
    "    # Otherwise the Algorithm will not be able to process it\n",
    "    numeric_inputs = []\n",
    "    string_inputs = []\n",
    "    for column in input_columns:\n",
    "        if str(indexed.schema[column].dataType) == 'StringType':\n",
    "            indexer = StringIndexer(inputCol=column, outputCol=column+\"_num\") \n",
    "            indexed = indexer.fit(indexed).transform(indexed)\n",
    "            new_col_name = column+\"_num\"\n",
    "            string_inputs.append(new_col_name)\n",
    "        else:\n",
    "            numeric_inputs.append(column)\n",
    "            \n",
    "    # Check globally for non normal data (using skewness and kurtosis)   \n",
    "    skew = df.select([f.skewness(c).alias(c) for c in df.columns if c in numeric_inputs]) # Calculate the skewness for all columns in the df\n",
    "    skew_array = skew.select(array(numeric_inputs).alias(\"skew\")) #create and array with results\n",
    "    #get the global min\n",
    "    skew_minimum = skew_array.select(array_min(skew_array.skew)).collect() # Collect golobal min as Python object\n",
    "    skew_minimum = skew_minimum[0][0] # Slice to get the number itself\n",
    "    #get the global max\n",
    "    skew_max = skew_array.select(array_max(skew_array.skew)).collect() # Collect golobal min as Python object\n",
    "    skew_max = skew_max[0][0] # Slice to get the number itself\n",
    "            \n",
    "    if skew_max >1 or skew_min < -1:\n",
    "        # Ask user if they want to floor and cap their data hollistically then act accordingly\n",
    "        # Let's use approxQuantile, otherwise it'll take FOREVER\n",
    "        # approxQuantile(cols: Array[String], probabilities: Array[Double], relativeError: Double): Array[Array[Double]] Permalink\n",
    "        # Calculates the approximate quantiles of numerical columns of a DataFrame.\n",
    "        print(\"Looks like your dataframe contains some non normal data which may contain outliers.\")\n",
    "        print(\"Would you like us to treat for that using flooring, capping and log(x+1) or e^(x+1)\")\n",
    "        print(\"This may help improve model accuracy.\")\n",
    "        floor_cap = str(input(\"Enter 1 for yes and 0 for no: \"))\n",
    "        if floor_cap == \"1\":\n",
    "            print(\"Okay, we are correcting for non normality now!\")\n",
    "            # empty dictionary d\n",
    "            d = {}\n",
    "            # Create a dictionary of quantiles\n",
    "            for col in numeric_inputs: \n",
    "                d[col] = indexed.approxQuantile(col,[0.01,0.99],0.25) #if you want to make it go faster increase the last number\n",
    "            #Now fill in the values\n",
    "            for col in numeric_inputs:\n",
    "                skew = indexed.agg(f.skewness(indexed[col])) #check for skewness\n",
    "                kurtosis = indexed.agg(f.kurtosis(indexed[col])) #check for kurtosis\n",
    "                # This function will floor, cap and then log+1 (just in case there are 0 values)\n",
    "                if skew > 1:\n",
    "                    indexed = indexed.withColumn(col, \\\n",
    "                    F.log(F.when(df[col] < d[col][0],d[col][0])\\\n",
    "                    .when(indexed[col] > d[col][1], d[col][1])\\\n",
    "                    .otherwise(indexed[col] ) +1).alias(col))\n",
    "                    print(col+\" has been treated for positive skewness)\n",
    "                if skew < -1:\n",
    "                    indexed = indexed.withColumn(col, \\\n",
    "                    F.exp(F.when(df[col] < d[col][0],d[col][0])\\\n",
    "                    .when(indexed[col] > d[col][1], d[col][1])\\\n",
    "                    .otherwise(indexed[col] ) +1).alias(col))\n",
    "                    print(col+\" has been treated for positive skewness)\n",
    "        elif floor_cap == \"0\":\n",
    "            print(\"Okay\") \n",
    "            print(\"We will return the dataframe without flooring and capping.\")\n",
    "        else:\n",
    "            print(\"You have entered an invalid response.\")\n",
    "            print(\"We will return the data without flooring and capping\")\n",
    "\n",
    "            \n",
    "    # Produce a warning if there are negative values in the dataframe that Naive Bayes cannot be used. \n",
    "    # Note: we only need to check the numeric input values since anything that is indexed won't have negative values\n",
    "    minimums = df.select([min(c).alias(c) for c in df.columns if c in numeric_inputs]) # Calculate the mins for all columns in the df\n",
    "    min_array = minimums.select(array(numeric_inputs).alias(\"mins\")) # Create an array for all mins and select only the input cols\n",
    "    df_minimum = min_array.select(array_min(min_array.mins)).collect() # Collect golobal min as Python object\n",
    "    df_minimum = df_minimum[0][0] # Slice to get the number itself\n",
    "\n",
    "    features_list = numeric_inputs + string_inputs\n",
    "    assembler = VectorAssembler(inputCols=features_list,outputCol='features')\n",
    "    output = assembler.transform(indexed).select('features','label')\n",
    "\n",
    "#     final_data = output.select('features','label') #drop everything else\n",
    "    \n",
    "    # Now check for negative values and ask user if they want to correct that? \n",
    "    if df_minimum < 0:\n",
    "        print(\"WARNING: The Naive Bayes Classifier will not be able to process your dataframe as it contains negative values\")\n",
    "        print(\"Would you like to correct that by rescaling all your features to a range of 0 to 1?\")\n",
    "        answer = str(input(\"Enter 1 for yes and 0 for no: \"))\n",
    "        print(\" \")\n",
    "    \n",
    "    if answer == \"1\":\n",
    "        print(\"Okay\")  \n",
    "        print(\"We are rescaling you dataframe....\")\n",
    "        scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "        # Compute summary statistics and generate MinMaxScalerModel\n",
    "        scalerModel = scaler.fit(output)\n",
    "\n",
    "        # rescale each feature to range [min, max].\n",
    "        scaled_data = scalerModel.transform(output)\n",
    "        final_data = scaled_data.select('label','scaledFeatures')\n",
    "        final_data = final_data.withColumnRenamed('scaledFeatures','features')\n",
    "        print(\"Done!\")\n",
    "\n",
    "    elif answer == \"0\":\n",
    "        print(\"Okay\") \n",
    "        print(\"We will return the dataframe unscaled.\")\n",
    "        final_data = output\n",
    "    else:\n",
    "        print(\"You have entered an invalid response.\")\n",
    "        print(\"We will return the data unscaled\")\n",
    "        final_data = output\n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take it for a test run!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to treat outliers in your data with flooring and capping?\n",
      "This may help improve model accuracy.\n",
      "Enter 1 for yes and 0 for no: 1\n",
      "Okay, we are flooring and capping your dataframe now!\n",
      "1-ZCRm done\n",
      "2-Energym done\n",
      "3-EnergyEntropym done\n",
      "4-SpectralCentroidm done\n",
      "5-SpectralSpreadm done\n",
      "6-SpectralEntropym done\n",
      "7-SpectralFluxm done\n",
      "8-SpectralRolloffm done\n",
      "9-MFCCs1m done\n",
      "10-MFCCs2m done\n",
      "11-MFCCs3m done\n",
      "12-MFCCs4m done\n",
      "13-MFCCs5m done\n",
      "14-MFCCs6m done\n",
      "15-MFCCs7m done\n",
      "16-MFCCs8m done\n",
      "17-MFCCs9m done\n",
      "18-MFCCs10m done\n",
      "19-MFCCs11m done\n",
      "20-MFCCs12m done\n",
      "21-MFCCs13m done\n",
      "22-ChromaVector1m done\n",
      "23-ChromaVector2m done\n",
      "24-ChromaVector3m done\n",
      "25-ChromaVector4m done\n",
      "26-ChromaVector5m done\n",
      "27-ChromaVector6m done\n",
      "28-ChromaVector7m done\n",
      "29-ChromaVector8m done\n",
      "30-ChromaVector9m done\n",
      "31-ChromaVector10m done\n",
      "32-ChromaVector11m done\n",
      "33-ChromaVector12m done\n",
      "34-ChromaDeviationm done\n",
      "35-ZCRstd done\n",
      "36-Energystd done\n",
      "37-EnergyEntropystd done\n",
      "38-SpectralCentroidstd done\n",
      "39-SpectralSpreadstd done\n",
      "40-SpectralEntropystd done\n",
      "41-SpectralFluxstd done\n",
      "42-SpectralRolloffstd done\n",
      "43-MFCCs1std done\n",
      "44-MFCCs2std done\n",
      "45-MFCCs3std done\n",
      "46-MFCCs4std done\n",
      "47-MFCCs5std done\n",
      "48-MFCCs6std done\n",
      "49-MFCCs7std done\n",
      "50-MFCCs8std done\n",
      "51-MFCCs9std done\n",
      "52-MFCCs10std done\n",
      "53-MFCCs11std done\n",
      "54-MFCCs12std done\n",
      "55-MFCCs13std done\n",
      "56-ChromaVector1std done\n",
      "57-ChromaVector2std done\n",
      "58-ChromaVector3std done\n",
      "59-ChromaVector4std done\n",
      "60-ChromaVector5std done\n",
      "61-ChromaVector6std done\n",
      "62-ChromaVector7std done\n",
      "63-ChromaVector8std done\n",
      "64-ChromaVector9std done\n",
      "65-ChromaVector10std done\n",
      "66-ChromaVector11std done\n",
      "67-ChromaVector12std done\n",
      "68-ChromaDeviationstd done\n",
      "69-BPM done\n",
      "70-BPMconf done\n",
      "71-BPMessentia done\n",
      "WARNING: The Naive Bayes Classifier will not be able to process your dataframe as it contains negative values\n",
      "Would you like to correct that by rescaling all your features to a range of 0 to 1?\n",
      "Enter 1 for yes and 0 for no: 1\n",
      " \n",
      "Okay\n",
      "We are rescaling you dataframe....\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>[0.5198182667002392, 0.3033899802582687, 0.895...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>[0.43529546399256597, 0.3739930090644269, 0.88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>[0.2970571291217422, 0.4467964877509512, 0.743...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>[0.3743526477343687, 0.5860529526571694, 0.796...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>[0.5864323374662597, 0.5186704525553854, 0.882...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features\n",
       "0   21.0  [0.5198182667002392, 0.3033899802582687, 0.895...\n",
       "1   21.0  [0.43529546399256597, 0.3739930090644269, 0.88...\n",
       "2   21.0  [0.2970571291217422, 0.4467964877509512, 0.743...\n",
       "3   21.0  [0.3743526477343687, 0.5860529526571694, 0.796...\n",
       "4   21.0  [0.5864323374662597, 0.5186704525553854, 0.882..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "input_columns = df.columns\n",
    "input_columns = input_columns[1:-1] # keep only relevant columns: everything but the first and last cols\n",
    "dependent_var = 'class'\n",
    "\n",
    "final_data = MLClassifierDFPrep(df,input_columns,dependent_var)\n",
    "final_data.limit(5).toPandas()\n",
    "# final_data.show(1,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split into Test and Training datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create all encompassing Classification Training and Evaluation Function\n",
    "\n",
    "Let's use our handy dandy function to train and test all our classifiers we have available to us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassTrainEval(classifier,features,classes):\n",
    "\n",
    "    def FindMtype(classifier):\n",
    "        # Intstantiate Model\n",
    "        M = classifier\n",
    "        # Learn what it is\n",
    "        Mtype = type(M).__name__\n",
    "        \n",
    "        return Mtype\n",
    "    \n",
    "    Mtype = FindMtype(classifier)\n",
    "\n",
    "\n",
    "    def IntanceFitModel(Mtype,classifier,classes,features):\n",
    "        \n",
    "        if Mtype == \"OneVsRest\":\n",
    "            # instantiate the base classifier.\n",
    "            lr = LogisticRegression()\n",
    "            # instantiate the One Vs Rest Classifier.\n",
    "            OVRclassifier = OneVsRest(classifier=lr)\n",
    "            fitModel = OVRclassifier.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            # specify layers for the neural network:\n",
    "            # input layer of size features, two intermediate of features+1 and same size as features\n",
    "            # and output of size number of classes\n",
    "            features_count = len(features[0][0])\n",
    "            layers = [features_count, features_count+1, features_count, classes]\n",
    "            MPC_classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "            fitModel = MPC_classifier.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2: #These classifiers currently only accept binary classification\n",
    "            print(Mtype,\" could not be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "            return\n",
    "#             fitModel = \"Not Acceptable\"\n",
    "#             return fitModel\n",
    "        if Mtype in(\"LogisticRegression\",\"NaiveBayes\",\"RandomForestClassifier\",\"GBTClassifier\",\"LinearSVC\",\"DecisionTreeClassifier\"):\n",
    "            # Fit Model\n",
    "            fitModel = classifier.fit(train)\n",
    "            return fitModel\n",
    "    \n",
    "    fitModel = IntanceFitModel(Mtype,classifier,classes,features)\n",
    "    \n",
    "    #Results:\n",
    "    columns = ['Classifier', 'Result']\n",
    "    \n",
    "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
    "        Mtype = [Mtype] # make this a string\n",
    "        score = [\"N/A\"]\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "    else:\n",
    "        predictions = fitModel.transform(test)\n",
    "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
    "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "        Mtype = [Mtype] # make this a string\n",
    "        score = [str(accuracy)] #make this a string and convert to a list\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run!\n",
    "# from pyspark.ml.classification import *\n",
    "# from pyspark.ml.evaluation import *\n",
    "# from pyspark.sql import functions as F\n",
    "\n",
    "# # Comment out Naive Bayes if your data still contains negative values\n",
    "# classifiers = [LogisticRegression()\n",
    "# #                ,OneVsRest()\n",
    "#                ,LinearSVC()\n",
    "#                ,NaiveBayes()\n",
    "#               ,RandomForestClassifier(),GBTClassifier(),DecisionTreeClassifier()\n",
    "#               ,MultilayerPerceptronClassifier()\n",
    "#               ] \n",
    "\n",
    "# features = final_data.select(['features']).collect()\n",
    "# # Learn how many classes there are in order to specify evaluation type based on binary or multi and turn the df into an object\n",
    "# class_count = final_data.select(F.countDistinct(\"label\")).collect()\n",
    "# classes = class_count[0][0]\n",
    "    \n",
    "# for classifier in classifiers:\n",
    "#     ClassTrainEval(classifier,final_data,features,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC  could not be used because PySpark currently only accepts binary classification data for this algorithm\n",
      "GBTClassifier  could not be used because PySpark currently only accepts binary classification data for this algorithm\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |42.93 |\n",
      "|OneVsRest                     |41.65 |\n",
      "|LinearSVC                     |N/A   |\n",
      "|NaiveBayes                    |29.67 |\n",
      "|RandomForestClassifier        |40.94 |\n",
      "|GBTClassifier                 |N/A   |\n",
      "|DecisionTreeClassifier        |36.37 |\n",
      "|MultilayerPerceptronClassifier|43.08 |\n",
      "+------------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run!\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Comment out Naive Bayes if your data still contains negative values\n",
    "classifiers = [LogisticRegression()\n",
    "               ,OneVsRest()\n",
    "               ,LinearSVC()\n",
    "               ,NaiveBayes()\n",
    "              ,RandomForestClassifier(),GBTClassifier(),DecisionTreeClassifier()\n",
    "              ,MultilayerPerceptronClassifier()\n",
    "              ] \n",
    "\n",
    "features = final_data.select(['features']).collect()\n",
    "# Learn how many classes there are in order to specify evaluation type based on binary or multi and turn the df into an object\n",
    "class_count = final_data.select(F.countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "\n",
    "#set up your results table\n",
    "columns = ['Classifier', 'Result']\n",
    "vals = [(\"Place Holder\",\"N/A\")]\n",
    "results = spark.createDataFrame(vals, columns)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    new_result = ClassTrainEval(classifier,features,classes)\n",
    "    results = results.union(new_result)\n",
    "results = results.where(\"Classifier!='Place Holder'\")\n",
    "results.show(100,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to tune!\n",
    "\n",
    "The accuracy rates were pretty poor our first go around. Let's see if we can try to improve the accuracy of our model using a kind of bagging method (ie. just replicate our dataframe x times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4600\n",
      "LinearSVC  could not be used because PySpark currently only accepts binary classification data for this algorithm\n",
      "GBTClassifier  could not be used because PySpark currently only accepts binary classification data for this algorithm\n",
      "6900\n",
      "LinearSVC  could not be used because PySpark currently only accepts binary classification data for this algorithm\n",
      "GBTClassifier  could not be used because PySpark currently only accepts binary classification data for this algorithm\n",
      "9200\n",
      "LinearSVC  could not be used because PySpark currently only accepts binary classification data for this algorithm\n",
      "GBTClassifier  could not be used because PySpark currently only accepts binary classification data for this algorithm\n",
      "11500\n",
      "LinearSVC  could not be used because PySpark currently only accepts binary classification data for this algorithm\n",
      "GBTClassifier  could not be used because PySpark currently only accepts binary classification data for this algorithm\n",
      "+------------------------------+------+------+------+------+------+\n",
      "|Classifier                    |Result|Result|Result|Result|Result|\n",
      "+------------------------------+------+------+------+------+------+\n",
      "|NaiveBayes                    |29.67 |37.01 |37.01 |37.01 |37.01 |\n",
      "|NaiveBayes                    |29.67 |37.01 |37.01 |37.01 |39.34 |\n",
      "|NaiveBayes                    |29.67 |37.01 |37.01 |37.01 |37.75 |\n",
      "|NaiveBayes                    |29.67 |37.01 |37.01 |37.01 |40.18 |\n",
      "|NaiveBayes                    |29.67 |37.01 |37.01 |39.34 |37.01 |\n",
      "|NaiveBayes                    |29.67 |37.01 |37.01 |39.34 |39.34 |\n",
      "|NaiveBayes                    |29.67 |37.01 |37.01 |39.34 |37.75 |\n",
      "|NaiveBayes                    |29.67 |37.01 |37.01 |39.34 |40.18 |\n",
      "|NaiveBayes                    |29.67 |37.01 |37.01 |37.75 |37.01 |\n",
      "|NaiveBayes                    |29.67 |37.01 |37.01 |37.75 |39.34 |\n",
      "|NaiveBayes                    |29.67 |37.01 |37.01 |37.75 |37.75 |\n",
      "|NaiveBayes                    |29.67 |37.01 |37.01 |37.75 |40.18 |\n",
      "|NaiveBayes                    |29.67 |37.01 |39.34 |37.01 |37.01 |\n",
      "|NaiveBayes                    |29.67 |37.01 |39.34 |37.01 |39.34 |\n",
      "|NaiveBayes                    |29.67 |37.01 |39.34 |37.01 |37.75 |\n",
      "|NaiveBayes                    |29.67 |37.01 |39.34 |37.01 |40.18 |\n",
      "|NaiveBayes                    |29.67 |37.01 |39.34 |39.34 |37.01 |\n",
      "|NaiveBayes                    |29.67 |37.01 |39.34 |39.34 |39.34 |\n",
      "|NaiveBayes                    |29.67 |37.01 |39.34 |39.34 |37.75 |\n",
      "|NaiveBayes                    |29.67 |37.01 |39.34 |39.34 |40.18 |\n",
      "|NaiveBayes                    |29.67 |37.01 |39.34 |37.75 |37.01 |\n",
      "|NaiveBayes                    |29.67 |37.01 |39.34 |37.75 |39.34 |\n",
      "|NaiveBayes                    |29.67 |37.01 |39.34 |37.75 |37.75 |\n",
      "|NaiveBayes                    |29.67 |37.01 |39.34 |37.75 |40.18 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |49.65 |49.65 |49.65 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |49.65 |49.65 |53.11 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |49.65 |49.65 |53.44 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |49.65 |49.65 |54.53 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |49.65 |53.11 |49.65 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |49.65 |53.11 |53.11 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |49.65 |53.11 |53.44 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |49.65 |53.11 |54.53 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |49.65 |53.44 |49.65 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |49.65 |53.44 |53.11 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |49.65 |53.44 |53.44 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |49.65 |53.44 |54.53 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |53.11 |49.65 |49.65 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |53.11 |49.65 |53.11 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |53.11 |49.65 |53.44 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |53.11 |49.65 |54.53 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |53.11 |53.11 |49.65 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |53.11 |53.11 |53.11 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |53.11 |53.11 |53.44 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |53.11 |53.11 |54.53 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |53.11 |53.44 |49.65 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |53.11 |53.44 |53.11 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |53.11 |53.44 |53.44 |\n",
      "|RandomForestClassifier        |40.94 |49.65 |53.11 |53.44 |54.53 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |48.96 |48.96 |48.96 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |48.96 |48.96 |51.24 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |48.96 |48.96 |52.44 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |48.96 |48.96 |51.81 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |48.96 |51.24 |48.96 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |48.96 |51.24 |51.24 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |48.96 |51.24 |52.44 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |48.96 |51.24 |51.81 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |48.96 |52.44 |48.96 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |48.96 |52.44 |51.24 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |48.96 |52.44 |52.44 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |48.96 |52.44 |51.81 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |51.24 |48.96 |48.96 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |51.24 |48.96 |51.24 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |51.24 |48.96 |52.44 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |51.24 |48.96 |51.81 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |51.24 |51.24 |48.96 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |51.24 |51.24 |51.24 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |51.24 |51.24 |52.44 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |51.24 |51.24 |51.81 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |51.24 |52.44 |48.96 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |51.24 |52.44 |51.24 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |51.24 |52.44 |52.44 |\n",
      "|MultilayerPerceptronClassifier|43.08 |48.96 |51.24 |52.44 |51.81 |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|GBTClassifier                 |N/A   |N/A   |N/A   |N/A   |N/A   |\n",
      "|OneVsRest                     |41.65 |53.59 |53.59 |53.59 |53.59 |\n",
      "|OneVsRest                     |41.65 |53.59 |53.59 |53.59 |57.82 |\n",
      "|OneVsRest                     |41.65 |53.59 |53.59 |53.59 |61.70 |\n",
      "|OneVsRest                     |41.65 |53.59 |53.59 |53.59 |61.64 |\n",
      "+------------------------------+------+------+------+------+------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dependent on running the above cell \n",
    "replicated_final_data = final_data\n",
    "\n",
    "#set up your results table\n",
    "columns = ['Classifier', 'Result']\n",
    "vals = [(\"Place Holder\",\"N/A\")]\n",
    "results2 = spark.createDataFrame(vals, columns)\n",
    "\n",
    "for y in range(0,4):\n",
    "    replicated_final_data = replicated_final_data.union(final_data)\n",
    "    print(replicated_final_data.count()) #for testing\n",
    "    train,test = replicated_final_data.randomSplit([0.7,0.3])\n",
    "    for classifier in classifiers:\n",
    "        new_result = ClassTrainEval(classifier,features,classes)\n",
    "        results2 = results2.union(new_result)\n",
    "    results2 = results2.where(\"Classifier!='Place Holder'\")\n",
    "    results = results.join(results2, [\"Classifier\"],\"inner\")\n",
    "\n",
    "results.show(100,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "Let's try to fine tune our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Diagnostics\n",
    "\n",
    "You can also generate some more detailed diagnostics on individual classifiers using this function too if you want. The output is pretty extensive, so I wouldn't do more than one at a time if I were you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.classification import *\n",
    "\n",
    "def ClassDiag(classifier):\n",
    "    \n",
    "    # Fit our model\n",
    "    C = classifier\n",
    "    fitModel = C.fit(train)\n",
    "\n",
    "    # Load the Summary\n",
    "    trainingSummary = fitModel.summary\n",
    "\n",
    "    # General Describe\n",
    "    trainingSummary.predictions.describe().show()\n",
    "\n",
    "    # View Predictions\n",
    "    pred_and_labels = fitModel.evaluate(test)\n",
    "    pred_and_labels.predictions.show()\n",
    "\n",
    "    # Print the coefficients and intercept for multinomial logistic regression\n",
    "    print(\"Coefficients: \\n\" + str(fitModel.coefficientMatrix))\n",
    "    print(\" \")\n",
    "    print(\"Intercept: \" + str(fitModel.interceptVector))\n",
    "    print(\" \")\n",
    "\n",
    "    # Obtain the objective per iteration\n",
    "    objectiveHistory = trainingSummary.objectiveHistory\n",
    "    print(\" \")\n",
    "    print(\"objectiveHistory:\")\n",
    "    for objective in objectiveHistory:\n",
    "        print(objective)\n",
    "\n",
    "    # for multiclass, we can inspect metrics on a per-label basis\n",
    "    print(\" \")\n",
    "    print(\"False positive rate by label:\")\n",
    "    for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "        print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"True positive rate by label:\")\n",
    "    for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "        print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Precision by label:\")\n",
    "    for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "        print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Recall by label:\")\n",
    "    for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "        print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"F-measure by label:\")\n",
    "    for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "        print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "    accuracy = trainingSummary.accuracy\n",
    "    falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "    truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "    fMeasure = trainingSummary.weightedFMeasure()\n",
    "    precision = trainingSummary.weightedPrecision\n",
    "    recall = trainingSummary.weightedRecall\n",
    "    print(\" \")\n",
    "    print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "          % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|             label|        prediction|\n",
      "+-------+------------------+------------------+\n",
      "|  count|              8051|              8051|\n",
      "|   mean|11.033039373990809|11.009191404794436|\n",
      "| stddev| 6.638689644020847| 6.657339104686515|\n",
      "|    min|               0.0|               0.0|\n",
      "|    max|              22.0|              22.0|\n",
      "+-------+------------------+------------------+\n",
      "\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|[0.01318905872279...|[7.87479333556950...|[0.04914783641675...|       1.0|\n",
      "|  0.0|[0.01583330335059...|[10.1707259208356...|[0.55651399545977...|       0.0|\n",
      "|  0.0|[0.01627302822802...|[10.9501217628170...|[0.90657454791735...|       0.0|\n",
      "|  0.0|[0.03309259147687...|[7.42821970087621...|[0.09096395797786...|       1.0|\n",
      "|  0.0|[0.06499457929863...|[6.71962922363719...|[0.79324737650469...|       0.0|\n",
      "|  0.0|[0.07324028771121...|[5.25878617941475...|[0.32491712824195...|       0.0|\n",
      "|  0.0|[0.07717873836592...|[12.1130259299836...|[0.78761593195247...|       0.0|\n",
      "|  0.0|[0.10353674221246...|[10.4545647199278...|[0.53901325148053...|       0.0|\n",
      "|  0.0|[0.12520897118489...|[3.06786961035840...|[0.01493821598554...|       6.0|\n",
      "|  0.0|[0.13110251563001...|[7.17209655762085...|[0.02476417701196...|       6.0|\n",
      "|  0.0|[0.13638120817696...|[7.80695875077978...|[0.27187086574589...|       6.0|\n",
      "|  0.0|[0.14116616389878...|[8.09204561091902...|[0.60537555679644...|       0.0|\n",
      "|  0.0|[0.14139946430197...|[9.06914395438925...|[4.07334706729801...|       5.0|\n",
      "|  0.0|[0.15290218852403...|[6.80999166741104...|[0.74770276174504...|       0.0|\n",
      "|  0.0|[0.15840187056460...|[7.97231801560174...|[0.65422840878002...|       0.0|\n",
      "|  0.0|[0.20097915078123...|[6.81600123955522...|[0.27558904906758...|      16.0|\n",
      "|  0.0|[0.20531727250904...|[8.37078070152619...|[0.38125732255542...|       1.0|\n",
      "|  0.0|[0.21107088873055...|[3.05567546649010...|[0.02247357293319...|      15.0|\n",
      "|  0.0|[0.21861938352692...|[8.34762628547058...|[0.77660428997418...|       0.0|\n",
      "|  0.0|[0.23669916775625...|[2.44474645463757...|[0.01755248485347...|       9.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Coefficients: \n",
      "DenseMatrix([[-1.19795771, -9.46406577,  0.68900607, ...,  3.85509185,\n",
      "               0.03482738, -6.52073585],\n",
      "             [-0.83409088, -9.09633393,  0.13240852, ..., -4.7179415 ,\n",
      "               5.46954021,  2.98067698],\n",
      "             [ 1.02659075, -5.23253585,  2.5677601 , ..., -1.49280597,\n",
      "               6.17456682,  6.33268757],\n",
      "             ...,\n",
      "             [ 1.0219087 ,  4.44211982,  5.09520696, ...,  7.26349749,\n",
      "              -5.4991621 , -5.06938548],\n",
      "             [-1.1487014 ,  3.66731274,  2.31816253, ..., -9.34330148,\n",
      "              -0.50476287,  2.22080762],\n",
      "             [ 1.59471178,  7.05672913,  2.67315324, ...,  6.29374133,\n",
      "              13.82790478,  2.10572058]])\n",
      " \n",
      "Intercept: [0.15677076425465997,0.051272722594778025,0.0010212898425895562,-0.0339933172340962,0.0355871184312565,0.018147226637892706,0.03674242200197555,0.015500495563593066,-0.13580203565909202,-0.04396455967895282,-0.02357089617670858,-0.04803414784205417,0.12711414415565422,0.015144846368684984,-0.05414911811924579,-0.04697306717788474,-0.029480342061121958,-0.005180904198181564,-0.006343198620277835,-0.042151970512293566,-0.00023174561951978554,-0.0027679521732293035,0.015342225221573755]\n",
      " \n",
      " \n",
      "objectiveHistory:\n",
      "3.135260894461815\n",
      "3.0114963375777606\n",
      "2.6449603903440932\n",
      "2.4088195526118326\n",
      "2.178486328840478\n",
      "2.0803694505684365\n",
      "2.0240038718269715\n",
      "2.0087726025335733\n",
      "2.002473735127819\n",
      "1.991850540038904\n",
      "1.9588590580548744\n",
      "1.897747675817162\n",
      "1.793294766339743\n",
      "1.7446544080294584\n",
      "1.6684079766257498\n",
      "1.6310053145119623\n",
      "1.6248906274349533\n",
      "1.621524247900533\n",
      "1.612431235755265\n",
      "1.6023479735740445\n",
      "1.5841949521425103\n",
      "1.5612893046436618\n",
      "1.531183467889737\n",
      "1.5131695113460546\n",
      "1.5048225594266162\n",
      "1.499101190620435\n",
      "1.4925645703402515\n",
      "1.4884857432404912\n",
      "1.4822270515031934\n",
      "1.461263462040453\n",
      "1.4420174957548868\n",
      "1.4209784323017731\n",
      "1.411051545563746\n",
      "1.4090949442414222\n",
      "1.4073083135558873\n",
      "1.402362156956398\n",
      "1.3922775109500007\n",
      "1.3788274134039562\n",
      "1.36997432804932\n",
      "1.360908236139136\n",
      "1.3571921395381632\n",
      "1.3540832014605635\n",
      "1.3459011754640549\n",
      "1.3428438878713203\n",
      "1.3326877611357215\n",
      "1.3292074690178401\n",
      "1.3269502688522048\n",
      "1.3245453391041224\n",
      "1.3178886551270403\n",
      "1.3077534365912988\n",
      "1.2973588167506263\n",
      "1.2886446430484049\n",
      "1.2852154663737092\n",
      "1.2843871439627086\n",
      "1.281019918681659\n",
      "1.2768614505114964\n",
      "1.2722979623658344\n",
      "1.2680378471613776\n",
      "1.2640964239316015\n",
      "1.2549710097828126\n",
      "1.2511865347593583\n",
      "1.2397254640638788\n",
      "1.2375044185270652\n",
      "1.23653716043998\n",
      "1.235447200339664\n",
      "1.2329659371938784\n",
      "1.2262771308449174\n",
      "1.2228077445957446\n",
      "1.2157470618933464\n",
      "1.213174920854442\n",
      "1.2123371925882078\n",
      "1.2111044583439745\n",
      "1.2083043563658264\n",
      "1.2044214848699113\n",
      "1.2002041556758023\n",
      "1.1971725058967362\n",
      "1.1957727307984098\n",
      "1.1937525218288514\n",
      "1.1891670737891007\n",
      "1.186711347838186\n",
      "1.1836418503189665\n",
      "1.1820447553662308\n",
      "1.1810589809477892\n",
      "1.1783019942937454\n",
      "1.1731526259114617\n",
      "1.1708388705504886\n",
      "1.1686293067929732\n",
      "1.1677225496757409\n",
      "1.1672744248633316\n",
      "1.165728809336089\n",
      "1.1618306069721007\n",
      "1.15832693836655\n",
      "1.1543020600328608\n",
      "1.1525381087331479\n",
      "1.1515529498885022\n",
      "1.1508434972965338\n",
      "1.1488478887246278\n",
      "1.147135793750949\n",
      "1.1454552478006799\n",
      "1.1447859449603388\n",
      "1.1437090259276588\n",
      " \n",
      "False positive rate by label:\n",
      "label 0: 0.02413390424289607\n",
      "label 1: 0.019600207684319835\n",
      "label 2: 0.00714100233705531\n",
      "label 3: 0.02142857142857143\n",
      "label 4: 0.0067523698221010255\n",
      "label 5: 0.014155844155844156\n",
      "label 6: 0.02093083723348934\n",
      "label 7: 0.013250194855806703\n",
      "label 8: 0.01671200932763311\n",
      "label 9: 0.01881894873458793\n",
      "label 10: 0.007268007787151201\n",
      "label 11: 0.016495648785556566\n",
      "label 12: 0.005844155844155844\n",
      "label 13: 0.022742040285899934\n",
      "label 14: 0.025977399662293805\n",
      "label 15: 0.01567560564840005\n",
      "label 16: 0.014289425824889582\n",
      "label 17: 0.01951092611862643\n",
      "label 18: 0.015342608243401378\n",
      "label 19: 0.01597195169458512\n",
      "label 20: 0.01556420233463035\n",
      "label 21: 0.019363222871994802\n",
      "label 22: 0.009357941252924357\n",
      " \n",
      "True positive rate by label:\n",
      "label 0: 0.5348837209302325\n",
      "label 1: 0.4899135446685879\n",
      "label 2: 0.8538681948424068\n",
      "label 3: 0.4757834757834758\n",
      "label 4: 0.8914285714285715\n",
      "label 5: 0.7008547008547008\n",
      "label 6: 0.6518105849582173\n",
      "label 7: 0.6855524079320113\n",
      "label 8: 0.6807228915662651\n",
      "label 9: 0.5057803468208093\n",
      "label 10: 0.8815028901734104\n",
      "label 11: 0.53125\n",
      "label 12: 0.8205128205128205\n",
      "label 13: 0.5\n",
      "label 14: 0.5170454545454546\n",
      "label 15: 0.6927710843373494\n",
      "label 16: 0.7507082152974505\n",
      "label 17: 0.465564738292011\n",
      "label 18: 0.5166666666666667\n",
      "label 19: 0.7142857142857143\n",
      "label 20: 0.5982404692082112\n",
      "label 21: 0.7247191011235955\n",
      "label 22: 0.7675070028011205\n",
      " \n",
      "Precision by label:\n",
      "label 0: 0.4972972972972973\n",
      "label 1: 0.5295950155763239\n",
      "label 2: 0.8441926345609065\n",
      "label 3: 0.5030120481927711\n",
      "label 4: 0.8571428571428571\n",
      "label 5: 0.6929577464788732\n",
      "label 6: 0.5924050632911393\n",
      "label 7: 0.7034883720930233\n",
      "label 8: 0.6366197183098592\n",
      "label 9: 0.546875\n",
      "label 10: 0.8448753462603878\n",
      "label 11: 0.5955414012738853\n",
      "label 12: 0.8648648648648649\n",
      "label 13: 0.5042492917847026\n",
      "label 14: 0.47643979057591623\n",
      "label 15: 0.6552706552706553\n",
      "label 16: 0.7066666666666667\n",
      "label 17: 0.5297805642633229\n",
      "label 18: 0.6118421052631579\n",
      "label 19: 0.6702412868632708\n",
      "label 20: 0.6296296296296297\n",
      "label 21: 0.6339066339066339\n",
      "label 22: 0.791907514450867\n",
      " \n",
      "Recall by label:\n",
      "label 0: 0.5348837209302325\n",
      "label 1: 0.4899135446685879\n",
      "label 2: 0.8538681948424068\n",
      "label 3: 0.4757834757834758\n",
      "label 4: 0.8914285714285715\n",
      "label 5: 0.7008547008547008\n",
      "label 6: 0.6518105849582173\n",
      "label 7: 0.6855524079320113\n",
      "label 8: 0.6807228915662651\n",
      "label 9: 0.5057803468208093\n",
      "label 10: 0.8815028901734104\n",
      "label 11: 0.53125\n",
      "label 12: 0.8205128205128205\n",
      "label 13: 0.5\n",
      "label 14: 0.5170454545454546\n",
      "label 15: 0.6927710843373494\n",
      "label 16: 0.7507082152974505\n",
      "label 17: 0.465564738292011\n",
      "label 18: 0.5166666666666667\n",
      "label 19: 0.7142857142857143\n",
      "label 20: 0.5982404692082112\n",
      "label 21: 0.7247191011235955\n",
      "label 22: 0.7675070028011205\n",
      " \n",
      "F-measure by label:\n",
      "label 0: 0.515406162464986\n",
      "label 1: 0.5089820359281437\n",
      "label 2: 0.849002849002849\n",
      "label 3: 0.4890190336749634\n",
      "label 4: 0.8739495798319327\n",
      "label 5: 0.6968838526912181\n",
      "label 6: 0.6206896551724139\n",
      "label 7: 0.6944045911047346\n",
      "label 8: 0.6579330422125182\n",
      "label 9: 0.5255255255255256\n",
      "label 10: 0.8628005657708628\n",
      "label 11: 0.5615615615615616\n",
      "label 12: 0.8421052631578947\n",
      "label 13: 0.5021156558533145\n",
      "label 14: 0.4959128065395096\n",
      "label 15: 0.6734992679355783\n",
      "label 16: 0.7280219780219781\n",
      "label 17: 0.4956011730205279\n",
      "label 18: 0.5602409638554218\n",
      "label 19: 0.6915629322268326\n",
      "label 20: 0.6135338345864662\n",
      "label 21: 0.6762778505897771\n",
      "label 22: 0.7795163584637269\n",
      " \n",
      "Accuracy: 0.649608744255372\n",
      "FPR: 0.01593577043218633\n",
      "TPR: 0.649608744255372\n",
      "F-measure: 0.648136958918412\n",
      "Precision: 0.6484686168720927\n",
      "Recall: 0.649608744255372\n"
     ]
    }
   ],
   "source": [
    "# classifier = LogisticRegression()\n",
    "ClassDiag(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
