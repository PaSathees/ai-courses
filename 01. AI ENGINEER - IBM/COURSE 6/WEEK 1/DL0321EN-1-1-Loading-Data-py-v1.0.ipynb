{"cells":[{"cell_type":"markdown","id":"d94c8bf3-04c5-4f4c-b33c-a204005a902e","metadata":{},"outputs":[],"source":["\u003ca href=\"https://cognitiveclass.ai/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\"\u003e\u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"400\"\u003e \u003c/a\u003e\n","\n","\u003ch1 align=center\u003e\u003cfont size = 5\u003eLoading Data\u003c/font\u003e\u003c/h1\u003e\n"]},{"cell_type":"markdown","id":"2a4c7406-d4b1-4926-bc1d-d379de61be2c","metadata":{},"outputs":[],"source":["\u003ch2\u003eObjective\u003c/h2\u003e\u003cul\u003e\u003cli\u003e How to download and visualize the image dataset.\u003c/li\u003e\u003c/ul\u003e \n"]},{"cell_type":"markdown","id":"7febf9d2-2c59-4d68-8ea2-0c648b9d976a","metadata":{},"outputs":[],"source":["## Introduction\n"]},{"cell_type":"markdown","id":"ff9801f5-dbcf-4dbf-9ca3-6a1a6342181d","metadata":{},"outputs":[],"source":["Crack detection has vital importance for structural health monitoring and inspection. In this series of labs, you learn everything you need to efficiently build a classifier using a pre-trained model that would detect cracks in images of concrete. For problem formulation, we will denote images of cracked concrete as the positive class and images of concrete with no cracks as the negative class.\n","\n","In this lab, I will walk you through the process of loading and visualizing the image dataset. \n","\n","**Please note**: You will encounter questions that you will need to answer in order to complete the quiz for this module.\n"]},{"cell_type":"markdown","id":"b6ac1a81-0808-4413-8520-0e22f808cbcf","metadata":{},"outputs":[],"source":["## Table of Contents\n","\n","\u003cdiv class=\"alert alert-block alert-info\" style=\"margin-top: 20px\"\u003e\n","\n","\u003cfont size = 3\u003e    \n","\n","1. \u003ca href=\"#item11\"\u003eDownload Data\u003c/a\u003e\n","2. \u003ca href=\"#item12\"\u003eImport Libraries and Packages\u003c/a\u003e  \n","3. \u003ca href=\"#item13\"\u003eLoad Images\u003c/a\u003e\n","\u003c/font\u003e\n","    \n","\u003c/div\u003e\n"]},{"cell_type":"markdown","id":"c90e09b2-7ea6-4b74-8dc3-f6935be09734","metadata":{},"outputs":[],"source":["   \n"]},{"cell_type":"markdown","id":"77bbed84-4902-46f9-9aa3-646d1a822079","metadata":{},"outputs":[],"source":["\u003ca id='item11'\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"31ffaf15-98c6-4515-8436-82f1dc36c3a6","metadata":{},"outputs":[],"source":["## Download Data\n"]},{"cell_type":"markdown","id":"91cd9223-46f2-4fd9-8741-5167fa24084b","metadata":{},"outputs":[],"source":["For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed.\n"]},{"cell_type":"code","id":"4dfea4f0-1e71-4407-ae1c-c90462ff1c18","metadata":{},"outputs":[],"source":["# get the data\n!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/concrete_crack_images_for_classification.zip"]},{"cell_type":"markdown","id":"b1d59611-aa29-4aa4-b7b7-8b80447ceb51","metadata":{},"outputs":[],"source":["And now if you check the left directory pane, you should see the zipped file *concrete_crack_images_for_classification.zip* appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running.\n"]},{"cell_type":"code","id":"7bef93f0-c2b8-408b-89f5-4c49ea3005fa","metadata":{},"outputs":[],"source":["!unzip concrete_crack_images_for_classification.zip"]},{"cell_type":"markdown","id":"2a3af913-81eb-4aa1-a552-53aa68d490d6","metadata":{},"outputs":[],"source":["Now, you should see two folders appear in the left pane: *Positive* and *Negative*. *Negative* is the negative class like we defined it earlier and it represents the concrete images with no cracks. *Positive* on the other hand is the positive class and represents the concrete images with cracks.\n"]},{"cell_type":"markdown","id":"d495cf9d-fd74-4387-9bbc-74bef64f01ba","metadata":{},"outputs":[],"source":["**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the folders. This may consume all of your memory and you may end up with a **50*** error. So please **DO NOT DO IT**.\n"]},{"cell_type":"markdown","id":"10f85bd7-eb57-4201-ae11-8135f38b5014","metadata":{},"outputs":[],"source":["   \n"]},{"cell_type":"markdown","id":"3753d0f4-896e-47d7-96dd-3d99a84c735c","metadata":{},"outputs":[],"source":["\u003ca id='item12'\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"5832eccc-be90-49cc-a1e3-373d16e2a312","metadata":{},"outputs":[],"source":["## Import Libraries and Packages\n"]},{"cell_type":"markdown","id":"ebbfb5c5-78e2-4daa-a2eb-97a31c5505a2","metadata":{},"outputs":[],"source":["Before we proceed, let's import the libraries and packages that we will need to complete the rest of this lab.\n"]},{"cell_type":"code","id":"2b86a706-db31-45e0-ac5e-fd174807762e","metadata":{},"outputs":[],"source":["import os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image"]},{"cell_type":"markdown","id":"42019386-100c-474e-a459-9ee3a5e68655","metadata":{},"outputs":[],"source":["  \n"]},{"cell_type":"markdown","id":"dbba7be9-e097-44cc-ba6e-d0572886b424","metadata":{},"outputs":[],"source":["\u003ca id='item13'\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"4600c046-77e0-4158-8c58-1bff091b6f94","metadata":{},"outputs":[],"source":["## Load Images\n"]},{"cell_type":"markdown","id":"09822663-4443-417d-8a1f-1f12e1ac59f7","metadata":{},"outputs":[],"source":["Next, we will use the standard approach of loading all images into memory and demonstrate how this approach is not efficient at all when it comes to building deep learning models for classifying images.\n"]},{"cell_type":"markdown","id":"b246121a-3b23-461b-8489-3008f2f8d375","metadata":{},"outputs":[],"source":["Let's start by reading in the negative images. First, we will use **os.scandir** to build an iterator to iterate through *./Negative* directory that contains all the images with no cracks.\n"]},{"cell_type":"code","id":"52235e19-405e-4734-826b-1acf938b4fe9","metadata":{},"outputs":[],"source":["negative_files = os.scandir('./Negative')\nnegative_files"]},{"cell_type":"markdown","id":"28a4923b-e23a-4bb7-b455-7b14469d8260","metadata":{},"outputs":[],"source":["Then, we will grab the first file in the directory.\n"]},{"cell_type":"code","id":"f58aee69-991e-45fc-86c5-0259f790cac6","metadata":{},"outputs":[],"source":["file_name = next(negative_files)\nfile_name"]},{"cell_type":"markdown","id":"181d1e19-3836-402d-8053-4ce18d0dd64e","metadata":{},"outputs":[],"source":["Since the directory can contain elements that are not files, we will only read the element if it is a file.\n"]},{"cell_type":"code","id":"0fe915bf-26d9-45b3-802c-b821627478f5","metadata":{},"outputs":[],"source":["os.path.isfile(file_name)"]},{"cell_type":"markdown","id":"c77b2d51-ae3f-4c2c-be39-14c0ea57e659","metadata":{},"outputs":[],"source":["Get the image name.\n"]},{"cell_type":"code","id":"b10b1d81-88ba-400d-b532-78079da8e2eb","metadata":{},"outputs":[],"source":["image_name = str(file_name).split(\"'\")[1]\nimage_name"]},{"cell_type":"markdown","id":"4563e60f-aa0f-4955-a0d9-1660de18a263","metadata":{},"outputs":[],"source":["Read in the image data.\n"]},{"cell_type":"code","id":"b79d6956-a684-459a-bc04-fdc4bfe38717","metadata":{},"outputs":[],"source":["image_data = plt.imread('./Negative/{}'.format(image_name))\nimage_data"]},{"cell_type":"markdown","id":"8a073c8d-5c6a-4ef7-b0f4-135d306bdbae","metadata":{},"outputs":[],"source":["### **Question**: What is the dimension of a single image according to **image_data**? \n"]},{"cell_type":"code","id":"0361f08e-b4b8-44c9-882b-c2f890380a43","metadata":{},"outputs":[],"source":["## You can use this cell to type your code to answer the above question\n\n"]},{"cell_type":"markdown","id":"51c1d192-c538-4d33-888c-6df9e1424d34","metadata":{},"outputs":[],"source":["Let's view the image.\n"]},{"cell_type":"code","id":"7335fb95-7de5-4cc4-ad68-3fe346835fc2","metadata":{},"outputs":[],"source":["plt.imshow(image_data)"]},{"cell_type":"markdown","id":"d4006e67-9201-48ff-b2c1-4ea73d0bfcbd","metadata":{},"outputs":[],"source":["Now that we are familiar with the process of reading in an image data, let's loop through all the image in the *./Negative* directory and read them all in and save them in the list **negative_images**. We will also time it to see how long it takes to read in all the images.\n"]},{"cell_type":"code","id":"c94db5cd-bcef-43f7-819a-72a354471cf1","metadata":{},"outputs":[],"source":["%%time\n\nnegative_images = []\nfor file_name in negative_files:\n    if os.path.isfile(file_name):\n        image_name = str(file_name).split(\"'\")[1]\n        image_data = plt.imread('./Negative/{}'.format(image_name))\n        negative_images.append(image_data)\n    \nnegative_images = np.array(negative_images)"]},{"cell_type":"markdown","id":"4f84945f-7ba0-4a20-a9ab-176a15ebc344","metadata":{},"outputs":[],"source":["Oops! The kernel died due to an out-of-memory error. Since the kernel died, you may have to run the above cell to load the libraries and packages again.\n","\n","Loading images into memory is definitely not the right approach when working with images as you can hit your limit on memory and other resources fairly quickly. Therefore, let's repeat the previous process but let's save the paths to the images in a variable instead of loading and saving the images themselves.\n"]},{"cell_type":"markdown","id":"9caaae61-1b21-4f24-a600-d9c0197f25a4","metadata":{},"outputs":[],"source":["So instead of using **os.scandir**, we will use **os.listdir**.\n"]},{"cell_type":"code","id":"d2d1f859-d699-43ea-b985-d8dbde4b72c2","metadata":{},"outputs":[],"source":["negative_images = os.listdir('./Negative')\nnegative_images"]},{"cell_type":"markdown","id":"557506db-a69a-43be-a151-c9c43a1d333e","metadata":{},"outputs":[],"source":["Notice how the images are not sorted, so let's call the \u003ccode\u003esort\u003c/code\u003e method to sort the images.\n"]},{"cell_type":"code","id":"669f3b27-1ec8-4872-afd6-e6609fb33a86","metadata":{},"outputs":[],"source":["negative_images.sort()\nnegative_images"]},{"cell_type":"markdown","id":"9b1e7531-b5b3-4faf-a868-3a3b359f2849","metadata":{},"outputs":[],"source":["Before we can show an image, we need to open it, which we can do using the **Image** module in the **PIL** library. So to open the first image, we run the following:\n"]},{"cell_type":"code","id":"6fd25c54-5e9c-44d4-bfbc-29dfbd0a8e32","metadata":{},"outputs":[],"source":["image_data = Image.open('./Negative/{}'.format(negative_images[0]))"]},{"cell_type":"markdown","id":"4ed08699-c0e5-4176-a278-4d6312bbf7e6","metadata":{},"outputs":[],"source":["Then to view the image, you can simply run:\n"]},{"cell_type":"code","id":"5240d329-db50-4cc2-99cf-52ef31361c8c","metadata":{},"outputs":[],"source":["image_data"]},{"cell_type":"markdown","id":"471ef7b5-e82a-4971-9dce-7a541b977f6a","metadata":{},"outputs":[],"source":["or use the \u003ccode\u003eimshow\u003c/code\u003e method as follows:\n"]},{"cell_type":"code","id":"82aa6ea2-37bb-42ac-8dac-72f7b394116d","metadata":{},"outputs":[],"source":["plt.imshow(image_data)"]},{"cell_type":"markdown","id":"2f27cde4-1554-482a-b1f9-63a4844a5944","metadata":{},"outputs":[],"source":["Let's loop through all the images in the \u003ccode\u003e./Negative\u003c/code\u003e directory and add save their paths.\n"]},{"cell_type":"code","id":"aed80fab-3ef8-48c5-b5a8-a2e146c77a98","metadata":{},"outputs":[],"source":["negative_images_dir = ['./Negative/{}'.format(image) for image in negative_images]\nnegative_images_dir"]},{"cell_type":"markdown","id":"667f8c6f-724a-4805-bc57-824242a18cec","metadata":{},"outputs":[],"source":["Let's check how many images with no cracks exist in the dataset.\n"]},{"cell_type":"code","id":"03111616-9b7d-410b-95f7-3da993fb743f","metadata":{},"outputs":[],"source":["len(negative_images_dir)"]},{"cell_type":"markdown","id":"0202b2a2-6f71-4a10-b02d-0edf5642e5f8","metadata":{},"outputs":[],"source":["### Question: Show the next four images.\n"]},{"cell_type":"code","id":"cf940546-fa3b-4158-9999-94102440a13c","metadata":{},"outputs":[],"source":["## You can use this cell to type your code to answer the above question\n\n\n\n\n\n\n\n"]},{"cell_type":"markdown","id":"f544515f-129d-4862-b0b8-0cd4184b794d","metadata":{},"outputs":[],"source":["**Your turn**: Save the paths to all the images in the *./Positive* directory in a list called **positive_images_dir**. Make sure to sort the paths.\n"]},{"cell_type":"code","id":"2d417606-fa65-4f80-a172-cf1020b9715a","metadata":{},"outputs":[],"source":["## Type your answer here\n\n\n\n\n\n"]},{"cell_type":"markdown","id":"cc721355-c044-40c9-96ba-2f6ecb797ff8","metadata":{},"outputs":[],"source":["### Question: How many images of cracked concrete exist in the *./Positive* directory?\n"]},{"cell_type":"code","id":"3d44f54a-e567-417a-a632-acc7d0fb5f5f","metadata":{},"outputs":[],"source":["## You can use this cell to type your code to answer the above question\n\n"]},{"cell_type":"markdown","id":"03fc89f8-cc8d-404f-9208-dccfc008011b","metadata":{},"outputs":[],"source":["### Question: Show the first four images with cracked concrete.\n"]},{"cell_type":"code","id":"13f0b106-ff1b-43a9-ad41-93b58fde35d8","metadata":{},"outputs":[],"source":["## You can use this cell to type your code to answer the above question\n\n\n\n\n\n"]},{"cell_type":"markdown","id":"55f9d840-b9aa-462c-887b-e2ed1149997e","metadata":{},"outputs":[],"source":[" \n"]},{"cell_type":"markdown","id":"dbbf500a-d78b-43fa-a502-ff399ad212f8","metadata":{},"outputs":[],"source":["### Thank you for completing this lab!\n","\n","This notebook was created by Alex Aklson. I hope you found this lab interesting and educational.\n"]},{"cell_type":"markdown","id":"38e248a9-8626-4c4b-a77e-62925ce88405","metadata":{},"outputs":[],"source":["This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week1_LAB1).\n"]},{"cell_type":"markdown","id":"dd3057c1-743b-4142-85f6-f659ad8342e8","metadata":{},"outputs":[],"source":["\u003ch2\u003eAbout the Authors:\u003c/h2\u003e \n","\n","\u003ca href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\"\u003eJoseph Santarcangelo\u003c/a\u003e has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"]},{"cell_type":"markdown","id":"98856968-475b-4298-84b7-0a4f8c97a371","metadata":{},"outputs":[],"source":[" [Alex Aklson](https://www.linkedin.com/in/aklson/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01). Ph.D., is a data scientist in the Digital Business Group at IBM Canada. Alex has been intensively involved in many exciting data science projects such as designing a smart system that could detect the onset of dementia in older adults using longitudinal trajectories of walking speed and home activity. Before joining IBM, Alex worked as a data scientist at Datascope Analytics, a data science consulting firm in Chicago, IL, where he designed solutions and products using a human-centred, data-driven approach. Alex received his Ph.D. in Biomedical Engineering from the University of Toronto.\n"]},{"cell_type":"markdown","id":"4a3ea493-9bfe-492b-ae11-60968c227964","metadata":{},"outputs":[],"source":["\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-18  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","\n"]},{"cell_type":"markdown","id":"48ed8e5e-ef00-4ff6-b306-e2471d7798ab","metadata":{},"outputs":[],"source":["\u003chr\u003e\n","\n","Copyright \u0026copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_medium=dswb\u0026utm_source=bducopyrightlink\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\u0026utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01).\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}